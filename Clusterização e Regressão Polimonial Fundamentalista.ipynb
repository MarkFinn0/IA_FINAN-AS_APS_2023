{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1443276f",
   "metadata": {},
   "source": [
    "# 1.Pré tratamento dos dados para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "001adca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c2993c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"Cuspidão\\Completao.csv\",delimiter=';',encoding=\"latin-1\",decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e52f9",
   "metadata": {},
   "source": [
    "# Criar variáveis gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8db85fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um variável com o nome de todos os setores do dataset e cria uma flag para se tem somente essa empresa no setor\n",
    "ListofCompanies=df.drop_duplicates(subset=['SETOR_ATIV','Nome Empresa'])\n",
    "ListofCompanies=ListofCompanies['SETOR_ATIV'].value_counts()\n",
    "ListofCompanies=pd.DataFrame(ListofCompanies)\n",
    "Listof1Companies=ListofCompanies[ListofCompanies['SETOR_ATIV']<4]\n",
    "ListofCompanies=ListofCompanies[ListofCompanies['SETOR_ATIV']>=4]\n",
    "ListofCompanies['Flag1Company']=0\n",
    "Listof1Companies['Flag1Company']=1\n",
    "ListofCompanies=pd.concat([ListofCompanies,Listof1Companies])\n",
    "ListofCompanies['SETOR_ATIV']=ListofCompanies.index\n",
    "\n",
    "#Cria Variáveis de Cuspir\n",
    "DF_Polyline=pd.DataFrame()\n",
    "DF_Cuspidao=pd.DataFrame()\n",
    "DF_Cuspidao2=pd.DataFrame()\n",
    "DF_Cuspidao_BAU=pd.DataFrame()\n",
    "DF_Cuspidao_RESTO=pd.DataFrame()\n",
    "df_produ_kmeans_REST_ALL=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cfec9",
   "metadata": {},
   "source": [
    "# Pré tratar dados para modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "45d57da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar ano e mes\n",
    "df['Ano']=df['DT_REFER'].apply(str).str[0:4]\n",
    "df['Mes']=df['DT_REFER'].apply(str).str[5:7]\n",
    "#Transformar colunas negativas em positivas\n",
    "df['Passivo Circulante']=df['Passivo Circulante']*-1\n",
    "df['Passivo Total']=df['Passivo Total']*-1\n",
    "#Coloca a Flag de 1 company no dataset central\n",
    "df1 = pd.merge( ListofCompanies,df, left_on='SETOR_ATIV', right_on='SETOR_ATIV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "69a55555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma as relações de indicadores para clusterizar em numeros, para o for andar de lado.\n",
    "df_produ[14]=df_produ['Ativo Circulante'].clip(lower=0)\n",
    "df_produ[13]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[12]=df_produ['Passivo Circulante'].clip(upper=0)\n",
    "df_produ[11]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[10]=df_produ['Passivo Total'].clip(upper=0)\n",
    "df_produ[9]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[8]=df_produ['Ativo Total'].clip(lower=0)\n",
    "df_produ[7]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[6]=df_produ['Reservas de Lucro'].clip(lower=0)\n",
    "df_produ[5]=df_produ['Receita'].clip(lower=0)\n",
    "df_produ[4]=df_produ['Receita'].clip(lower=0)\n",
    "df_produ[3]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[2]=df_produ['Receita'].clip(lower=0)\n",
    "df_produ[1]=df_produ['Lucro/Prejuízo do Período'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ddd54",
   "metadata": {},
   "source": [
    "# Clusterizar as empresas com dados realizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8160b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provisorio=df_produ\n",
    "df_provisorio=df_provisorio[['Nome Empresa',\n",
    "                             'Ticker',\n",
    "                             'SETOR_ATIV',\n",
    "                             'Flag1Company',\n",
    "                             'DT_REFER',\n",
    "                             'Ano',\n",
    "                             'Mes',\n",
    "                             1,2,3,4,5,6,7,8,9,10,11,12,13,14]]\n",
    "#BAU KMEANS\n",
    "for y in range(1,13):\n",
    "    for x in ListofCompanies.index.values:\n",
    "        if y==1:\n",
    "            y1=1\n",
    "            y2=2\n",
    "        else:\n",
    "            y1=y+1\n",
    "            y2=y+2\n",
    "        #filtra o setor\n",
    "        df_produ_kmeans=df_provisorio[(df_provisorio['SETOR_ATIV']==x)&(df_provisorio['Flag1Company']==0)].reset_index(drop=True)\n",
    "        AnoMAX=df_produ_kmeans['DT_REFER'].apply(str).str[0:4].max()\n",
    "        MesMAX=df_produ_kmeans['DT_REFER'].apply(str).str[5:7].max()\n",
    "        #Filtrar ano e mês (ultimo tri de cada setor)\n",
    "        df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[\"Ano\"]==AnoMAX)&(df_produ_kmeans[\"Mes\"]==MesMAX)].reset_index(drop=True)      \n",
    "        #Clusteriza as empresas com valores negativos como 0 (ruim)\n",
    "        df_produ_kmeans_REST_NO=df_produ_kmeans[(df_produ_kmeans[y1]==0)|(df_produ_kmeans[y2]==0)].reset_index(drop=True)\n",
    "        df_produ_kmeans_REST_NO[f\"{y1}{y2} Cluster\"]=0\n",
    "        #Separa as empresas que são elegíveis a escalabilidade e a clusterização\n",
    "        df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[y1]!=0)&(df_produ_kmeans[y2]!=0)].reset_index(drop=True)\n",
    "        df_produ_kmeans=df_produ_kmeans.sort_values(by=[y1,y2]).reset_index(drop=True)\n",
    "        \n",
    "        #se tiver mais de 1 amostra (empresa)\n",
    "        if len(df_produ_kmeans)>=2:\n",
    "            #FAÇO A ESCALABILIDADE COM STANDARD\n",
    "            scaler = StandardScaler() \n",
    "            pca = PCA(n_components = 2) \n",
    "            features= df_produ_kmeans[[y1,y2]]\n",
    "            scaled_df = scaler.fit_transform(features) \n",
    "            normalized_df = normalize(scaled_df) \n",
    "            normalized_df = pd.DataFrame(normalized_df)\n",
    "            #E DEPOIS REDUZO AS DIMENSÕES E CORRELAÇÕES COM O PCA\n",
    "            X_principal = pca.fit_transform(normalized_df) \n",
    "            features = pd.DataFrame(X_principal) \n",
    "            features.columns = ['P1', 'P2']\n",
    "            c=3\n",
    "            if len(features)<3:\n",
    "                c=len(features)\n",
    "                \n",
    "            #DOU UM FIT NO KMEANS\n",
    "            kmeans = KMeans(n_clusters=c, init='random',\n",
    "                        n_init=10,\n",
    "                        max_iter=300,random_state=0)\n",
    "            kmeans.fit(features)\n",
    "            #DPS EU FAÇO A CLUSTERIZAÇÃO\n",
    "            d = KMeans(n_clusters=c, init='random',\n",
    "                        n_init=10,\n",
    "                        max_iter=300,random_state=0).fit_predict(features)\n",
    "            df_produ_kmeans[f\"{y1}{y2} Cluster\"]=d\n",
    "            DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "            DF_Cuspidao_BAU=pd.concat([DF_Cuspidao2,DF_Cuspidao_BAU]).reset_index(drop=True)\n",
    "        else:\n",
    "            DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "            DF_Cuspidao_BAU=pd.concat([DF_Cuspidao2,DF_Cuspidao_BAU]).reset_index(drop=True)\n",
    "    df_provisorio=DF_Cuspidao_BAU\n",
    "    DF_Cuspidao2=pd.DataFrame()\n",
    "    DF_Cuspidao_BAU=pd.DataFrame()\n",
    "    \n",
    "DF_Cuspidao_BAU=df_provisorio\n",
    "DF_Cuspidao=pd.DataFrame()\n",
    "df_provisorio=df_produ\n",
    "df_provisorio=df_provisorio[['Nome Empresa',\n",
    "                             'Ticker',\n",
    "                             'SETOR_ATIV',\n",
    "                             'Flag1Company',\n",
    "                             'DT_REFER',\n",
    "                             'Ano',\n",
    "                             'Mes',\n",
    "                             1,2,3,4,5,6,7,8,9,10,11,12,13,14]]\n",
    "#REJEITADOS KMEANS\n",
    "for y in range(1,13):\n",
    "    if y==1:\n",
    "        y1=1\n",
    "        y2=2\n",
    "    else:\n",
    "        y1=y+1\n",
    "        y2=y+2\n",
    "    #filtra o setor\n",
    "    df_produ_kmeans=df_provisorio[(df_provisorio['Flag1Company']==1)].reset_index(drop=True)\n",
    "    AnoMAX=df_produ_kmeans['DT_REFER'].apply(str).str[0:4].max()\n",
    "    MesMAX=df_produ_kmeans['DT_REFER'].apply(str).str[5:7].max()\n",
    "    #Filtrar ano e mês (ultimo tri de cada setor)\n",
    "    df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[\"Ano\"]==AnoMAX)&(df_produ_kmeans[\"Mes\"]==MesMAX)].reset_index(drop=True)\n",
    "    #Clusteriza as empresas com valores negativos como 0 (ruim)\n",
    "    df_produ_kmeans_REST_NO=df_produ_kmeans[(df_produ_kmeans[y1]==0)|(df_produ_kmeans[y2]==0)].reset_index(drop=True)\n",
    "    df_produ_kmeans_REST_NO[f\"{y1}{y2} Cluster\"]=0\n",
    "    #Separa as empresas que são elegíveis a escalabilidade e a clusterização\n",
    "    df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[y1]!=0)&(df_produ_kmeans[y2]!=0)].reset_index(drop=True)\n",
    "    df_produ_kmeans=df_produ_kmeans.sort_values(by=[y1,y2]).reset_index(drop=True)\n",
    "    #se tiver mais de 1 amostra (empresa)\n",
    "    if len(df_produ_kmeans)>=2:\n",
    "        #FAÇO A ESCALABILIDADE COM STANDARD\n",
    "        scaler = StandardScaler() \n",
    "        pca = PCA(n_components = 2) \n",
    "        features= df_produ_kmeans[[y1,y2]]\n",
    "        scaled_df = scaler.fit_transform(features) \n",
    "        normalized_df = normalize(scaled_df) \n",
    "        normalized_df = pd.DataFrame(normalized_df)\n",
    "        #E DEPOIS REDUZO AS DIMENSÕES E CORRELAÇÕES COM O PCA\n",
    "        X_principal = pca.fit_transform(normalized_df) \n",
    "        features = pd.DataFrame(X_principal) \n",
    "        features.columns = ['P1', 'P2']\n",
    "        c=3\n",
    "        if len(features)<3:\n",
    "            c=len(features)\n",
    "        #DOU UM FIT NO KMEANS\n",
    "        kmeans = KMeans(n_clusters=c, init='random',\n",
    "                    n_init=10,\n",
    "                    max_iter=300,random_state=0)\n",
    "        kmeans.fit(features)\n",
    "        #DPS EU FAÇO A CLUSTERIZAÇÃO\n",
    "        d = KMeans(n_clusters=c, init='random',\n",
    "                    n_init=10,\n",
    "                    max_iter=300,random_state=0).fit_predict(features)\n",
    "        df_produ_kmeans[f\"{y1}{y2} Cluster\"]=d\n",
    "        DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "        DF_Cuspidao_RESTO=pd.concat([DF_Cuspidao2,DF_Cuspidao_RESTO]).reset_index(drop=True)\n",
    "    else:\n",
    "        DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "        DF_Cuspidao_RESTO=pd.concat([DF_Cuspidao2,DF_Cuspidao_RESTO]).reset_index(drop=True)\n",
    "    df_provisorio=DF_Cuspidao_RESTO\n",
    "    DF_Cuspidao2=pd.DataFrame()\n",
    "    DF_Cuspidao_RESTO=pd.DataFrame()\n",
    "DF_kmeans=pd.concat([DF_Cuspidao_BAU,df_provisorio]).reset_index(drop=True)\n",
    "DF_kmeans[\"Dados\"]=\"Realizado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6b3a891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_kmeans=DF_kmeans[['Nome Empresa','Ticker','SETOR_ATIV','DT_REFER',\"Dados\",\n",
    "             1,2,3,4,5,6,7,8,9,10,11,12,13,14,\n",
    "            '12 Cluster',\n",
    "            '34 Cluster',\n",
    "            '56 Cluster',\n",
    "            '78 Cluster',\n",
    "            '910 Cluster',\n",
    "            '1112 Cluster',\n",
    "            '1314 Cluster',\n",
    "             ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8d4dc",
   "metadata": {},
   "source": [
    "# Prever os próximos 4 tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "38755ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separo os indicadores que eu quero prever\n",
    "df_produ[11]=df_produ['Obrigações Fiscais']\n",
    "df_produ[10]=df_produ['Obrigações Sociais e Trabalhistas']\n",
    "df_produ[9]=df_produ['Contas a Receber']\n",
    "df_produ[8]=df_produ['Ativo Circulante']\n",
    "df_produ[7]=df_produ['Passivo Circulante']\n",
    "df_produ[6]=df_produ['Passivo Total']\n",
    "df_produ[5]=df_produ['Ativo Total']\n",
    "df_produ[4]=df_produ['Reservas de Lucro']\n",
    "df_produ[3]=df_produ['Patrimônio Líquido']\n",
    "df_produ[2]=df_produ['Receita']\n",
    "df_produ[1]=df_produ['Lucro/Prejuízo do Período']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "94532911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provisorio=df_produ\n",
    "df_provisorio=df_provisorio[['Nome Empresa',\n",
    "                             'Ticker',\n",
    "                             'SETOR_ATIV',\n",
    "                             'Flag1Company',\n",
    "                             'DT_REFER',\n",
    "                             'Ano',\n",
    "                             'Mes',\n",
    "                             1,2,3,4,5,6,7,8,9,10,11]]\n",
    "\n",
    "#pego a lista de empresas para analisar\n",
    "LitsofTickers=df_provisorio.drop_duplicates(subset='Ticker')\n",
    "LitsofTickers=LitsofTickers['Ticker'].values\n",
    "for x in LitsofTickers:\n",
    "    DF_Poly=df_provisorio[df_provisorio['Ticker']==x].reset_index(drop=True)\n",
    "    DF_Poly.sort_values(by=['DT_REFER']).reset_index(drop=True)\n",
    "    #transformo os indexes em variáveis e a data em datetime\n",
    "    DF_Poly[\"indexes\"]=DF_Poly.index\n",
    "    DF_Poly['DT_REFER']=pd.to_datetime(DF_Poly['DT_REFER'])\n",
    "    #pego a ultima linha dessa empresa para pegar as informações principais para criar um novo dataset\n",
    "    Lastmonth=DF_Poly.iloc[-1]['DT_REFER']\n",
    "    Lastname=DF_Poly.iloc[-1]['Nome Empresa']\n",
    "    Lastsector=DF_Poly.iloc[-1]['SETOR_ATIV']\n",
    "    Lastnamesub=DF_Poly.iloc[-1]['Ticker']\n",
    "    Lastindex=DF_Poly.iloc[-1]['indexes']\n",
    "    #Crio as datas que eu quero ver la na frente,baseado na data do ultimo balanço\n",
    "    Lastmonth1=Lastmonth+ relativedelta(months=+3)\n",
    "    Lastmonth2=Lastmonth+ relativedelta(months=+6)\n",
    "    Lastmonth3=Lastmonth+ relativedelta(months=+9)\n",
    "    Lastmonth4=Lastmonth+ relativedelta(months=+12)\n",
    "    #Crio um dataframe novo com essas datas\n",
    "    Dateto=pd.DataFrame({'Data_REF': [Lastmonth1,Lastmonth2,Lastmonth3,Lastmonth4]})\n",
    "    X_seq=pd.DataFrame({'x': [Lastindex+1,Lastindex+2,Lastindex+3,Lastindex+4]})\n",
    "    #Configuro o modelo polimonial\n",
    "    polyreg=make_pipeline(PolynomialFeatures(3),LinearRegression())\n",
    "    Pred=Dateto\n",
    "    Pred[\"Nome Empresa\"]=Lastname\n",
    "    Pred['Ticker']=Lastnamesub\n",
    "    Pred['SETOR_ATIV']=Lastsector\n",
    "    #Leio o historico de todos os indicadores e faço a previsão\n",
    "    for y in range(1,12):\n",
    "        yy=DF_Poly[['indexes']]\n",
    "        xx=DF_Poly[[y]]\n",
    "        polyreg.fit(yy,xx)\n",
    "        Pred2=polyreg.predict(X_seq)\n",
    "        Pred2=pd.DataFrame(Pred2,columns=[y])\n",
    "        Pred[y]=Pred2\n",
    "    DF_Polyline=pd.concat([Pred,DF_Polyline]).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "DF_Polyline['Ano']=DF_Polyline['Data_REF'].apply(str).str[0:4]\n",
    "DF_Polyline['Mes']=DF_Polyline['Data_REF'].apply(str).str[5:7]\n",
    "DF_Polyline['Dados']=\"Previsão\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b6ef5",
   "metadata": {},
   "source": [
    "# Organizar os dados para cuspir no Front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "934c0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_kmeans=DF_kmeans.fillna(0)\n",
    "#Separo as colunas principais do dataset Kmeans e dou um replace nas clusterizações para criar uma nota\n",
    "DF_kmeans_2=DF_kmeans.loc[:,('Ticker','DT_REFER',\"Dados\",'12 Cluster',\n",
    "            '34 Cluster',\n",
    "            '56 Cluster',\n",
    "            '78 Cluster',\n",
    "            '910 Cluster',\n",
    "            '1112 Cluster',\n",
    "            '1314 Cluster')].replace([0,1,2],[0,10,5])\n",
    "#Crio a nota da empresa baseada nos clusters (0 é ruim, 1 é bom e 2 é mediano)\n",
    "DF_kmeans_2['Nota da Empresa']=DF_kmeans_2['12 Cluster']+DF_kmeans_2['34 Cluster']+DF_kmeans_2['56 Cluster']+DF_kmeans_2['78 Cluster']+DF_kmeans_2['910 Cluster']+DF_kmeans_2['1112 Cluster']+DF_kmeans_2['1314 Cluster']\n",
    "DF_kmeans_2['Nota da Empresa']=DF_kmeans_2['Nota da Empresa']/7\n",
    "DF_kmeans_2['Desempenho do Trimestre']=np.where(DF_kmeans_2['Nota da Empresa']<5,\"Ruim\",\n",
    "                                        (np.where((DF_kmeans_2['Nota da Empresa']>=5) & (DF_kmeans_2['Nota da Empresa']<7) ,\"Médio\",\"Bom\")))\n",
    "#Pego o indicador com a melhor nota de clusterização (indicador denominador)\n",
    "DF_kmeans_2['Melhor Indicador1']=(DF_kmeans_2['12 Cluster']+DF_kmeans_2['34 Cluster']+DF_kmeans_2['56 Cluster'])/3\n",
    "DF_kmeans_2['Melhor Indicador2']=(DF_kmeans_2['34 Cluster']+DF_kmeans_2['78 Cluster']+DF_kmeans_2['910 Cluster']+DF_kmeans_2['1112 Cluster']+DF_kmeans_2['1314 Cluster'])/5\n",
    "DF_kmeans_2['Melhor Indicador']=np.where(DF_kmeans_2['Melhor Indicador1']>DF_kmeans_2['Melhor Indicador2'],\"Receita\",\n",
    "                                        (np.where(DF_kmeans_2['Melhor Indicador1']<DF_kmeans_2['Melhor Indicador2'],\"Patrimônio Líquido\",\"Nenhum\")))\n",
    "df_produ=df1\n",
    "#Pego as colunas antigas sem tratamento de clips\n",
    "DF_kmeans_2 = pd.merge(df_produ,DF_kmeans_2 ,left_on=['Ticker','DT_REFER'], right_on=['Ticker','DT_REFER'])\n",
    "DF_kmeans_2['Analise']=DF_kmeans_2['Flag1Company'].replace([0,1],[\"Analise por Setor\",'Analise com outras empresas'])\n",
    "DF_kmeans_2['Tipo de Analise']='Kmeans'\n",
    "#Deixo tudo limpinho e arrumado no dataset kmeans\n",
    "DF_kmeans_2=DF_kmeans_2[['Nome Empresa','Ticker','SETOR_ATIV','Dados','Analise','Melhor Indicador','Desempenho do Trimestre','DT_REFER','Lucro/Prejuízo do Período','Ativo Total','Ativo Circulante','Contas a Receber','Passivo Total','Passivo Circulante','Obrigações Sociais e Trabalhistas','Obrigações Fiscais','Reservas de Lucro','Patrimônio Líquido']]\n",
    "#Dou nome aos bois no dataset do polimonial\n",
    "DF_Polyline_2=DF_Polyline.rename({'Data_REF': 'DT_REFER', \n",
    "                                  1: 'Lucro/Prejuízo do Período',\n",
    "                                  2: 'Receita', \n",
    "                                  3: 'Patrimônio Líquido', \n",
    "                                  4: 'Reservas de Lucro', \n",
    "                                  5: 'Ativo Total',\n",
    "                                  6: 'Passivo Total', \n",
    "                                  7: 'Passivo Circulante', \n",
    "                                  8: 'Ativo Circulante',\n",
    "                                  9: 'Contas a Receber',\n",
    "                                  10: 'Obrigações Sociais e Trabalhistas',\n",
    "                                  11: 'Obrigações Fiscais',\n",
    "                                 }, axis=1)\n",
    "#Seto as mesmas colunas do kmeans\n",
    "DF_Polyline_2['Melhor Indicador']='Não Analisado'\n",
    "DF_Polyline_2['Desempenho do Trimestre']='Não Analisado'\n",
    "DF_Polyline_2['Nota da Empresa']='Não Analisado'\n",
    "DF_Polyline_2['Analise']='Analise de Historico Financeiro'\n",
    "DF_Polyline_2['Tipo de Analise']='Regressão Polimonial'\n",
    "#Deixo tudo limpinho e arrumado no dataset polimonial\n",
    "DF_Polyline_2=DF_Polyline_2[['Nome Empresa','Ticker','SETOR_ATIV','Dados','Analise','Melhor Indicador','Desempenho do Trimestre','DT_REFER','Lucro/Prejuízo do Período','Ativo Total','Ativo Circulante','Contas a Receber','Passivo Total','Passivo Circulante','Obrigações Sociais e Trabalhistas','Obrigações Fiscais','Reservas de Lucro','Patrimônio Líquido']]\n",
    "#Deipois junto tudo e cuspo\n",
    "Base_Unica=pd.concat([DF_Polyline_2,DF_kmeans_2]).reset_index(drop=True)\n",
    "Base_Unica.to_csv(rf\"Cuspidão\\Base_Unica.csv\",decimal=',',sep=';', encoding='latin-1',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
